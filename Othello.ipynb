{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Othello\n",
    "\n",
    "Othello is a turn-based two-player strategy board game. The players take turns placing pieces, one player white and the other player black, on an 8x8 board in such a way that captures some of the opponent's pieces, with the goal of finishing the game with more pieces of their color on the board.\n",
    "\n",
    "Every move must capture one or more of the opponent's pieces. To capture, player A places a piece adjacent to one of player B's pieces so that there is a straight line (horizontal, vertical or diagonal) of adjacent pieces that begins with one of player A's pieces, continues with one or more of player B's pieces, and ends with one of player A's pieces.\n",
    "\n",
    "For example, if Black places a piece on square (5, 1), he will capture all of Black's pieces (5, 1) and (5, 6):\n",
    "\n",
    "<img src='files/img/capture.png'>\n",
    "\n",
    "For more information about the game (which is also known as Reversi) including detailed rules, see the entry on [Wikipedia](https://en.wikipedia.org/wiki/Reversi). Additionally, this implementation doesn't take into account some tournament-style Othello details, such as game time limits and a different indexing scheme.\n",
    "\n",
    "We will implement representations for the board and pieces and the mechanics of playing a game. We will then explore several game-playing strategies. There is a simple command-line program provided for playing against the computer or comparing two strategies.\n",
    "\n",
    "Written by [Daniel Connelly](http://dhconnelly.com). This implementation follows chapter 18 of Peter Norvig's \"Paradigms of Artificial Intelligence\".\n",
    "\n",
    "## Table of contents\n",
    "\n",
    "1. [Board representation](#board)\n",
    "2. [Playing the game](#playing)\n",
    "3. [Strategies](#strategies)\n",
    "   - [Random](#random)<br>\n",
    "   - [Local maximization](#localmax)<br>\n",
    "   - [Minimax search](#minimax)<br>\n",
    "   - [Alpha-beta search](#alphabeta)<br>\n",
    "4. [Conclusion](#conclusion)\n",
    "\n",
    "<a id=\"board\"></a>\n",
    "\n",
    "## Board Representation\n",
    "\n",
    "We represent the board as a 100-element list, which includes each square on the board as well as the outside edge. Each consecutive sublist of ten elements represents a single row, and each list element stores a piece. An initial board contains four pieces in the center:\n",
    "\n",
    "```\n",
    "     ? ? ? ? ? ? ? ? ? ?\n",
    "     ? . . . . . . . . ?\n",
    "     ? . . . . . . . . ?\n",
    "     ? . . . . . . . . ?\n",
    "     ? . . . o @ . . . ?\n",
    "     ? . . . @ o . . . ?\n",
    "     ? . . . . . . . . ?\n",
    "     ? . . . . . . . . ?\n",
    "     ? . . . . . . . . ?\n",
    "     ? ? ? ? ? ? ? ? ? ?\n",
    "```\n",
    "\n",
    "This representation has two useful properties:\n",
    "1. Square (m, n) can be accessed as `board[mn]`. This avoids the need to write functions that convert between square locations and list indexes.\n",
    "2. Operations involving bounds checking are slightly simpler.\n",
    "\n",
    "The outside edge is marked `?`, empty squares are `.`, black is `@`, and white is `o`. The black and white pieces represent the two players."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMPTY, BLACK, WHITE, OUTER = '.', '@', 'o', '?'\n",
    "PIECES = (EMPTY, BLACK, WHITE, OUTER)\n",
    "PLAYERS = {BLACK: 'Black', WHITE: 'White'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To refer to neighbor squares we can add a direction to a square."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "UP, DOWN, LEFT, RIGHT = -10, 10, -1, 1\n",
    "UP_RIGHT, DOWN_RIGHT, DOWN_LEFT, UP_LEFT = -9, 11, 9, -11\n",
    "DIRECTIONS = (UP, UP_RIGHT, RIGHT, DOWN_RIGHT, DOWN, DOWN_LEFT, LEFT, UP_LEFT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1 2 3 4 5 6 7 8\n",
      "1 . . . . . . . .\n",
      "2 . . . . . . . .\n",
      "3 . . . . . . . .\n",
      "4 . . . o @ . . .\n",
      "5 . . . @ o . . .\n",
      "6 . . . . . . . .\n",
      "7 . . . . . . . .\n",
      "8 . . . . . . . .\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def squares():\n",
    "    \"\"\"List all the valid squares on the board\"\"\"\n",
    "    return [i for i in range(11, 89) if 1 <= (i % 10) <= 8]\n",
    "\n",
    "def initial_board():\n",
    "    \"\"\"Create a new board with the initial black and white positions filled\"\"\"\n",
    "    board = [OUTER] * 100\n",
    "    for i in squares():\n",
    "        board[i] = EMPTY\n",
    "    # The middle four squares should hold the initial piece positions.\n",
    "    board[44], board[45] = WHITE, BLACK\n",
    "    board[54], board[55] = BLACK, WHITE\n",
    "    return board\n",
    "\n",
    "def print_board(board):\n",
    "    \"\"\"Get a string representation of the board.\"\"\"\n",
    "    rep = ''\n",
    "    rep += '  {0}\\n'.format(' '.join(map(str, range(1, 9))))\n",
    "    for row in range(1, 9):\n",
    "        begin, end = 10*row + 1, 10*row + 9\n",
    "        rep += '{0} {1}\\n'.format(row, ' '.join(board[begin:end]))\n",
    "    return rep\n",
    "\n",
    "print(print_board(initial_board()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"playing\"></a>\n",
    "\n",
    "## Playing the Game\n",
    "\n",
    "We need functions to get moves from players, check to make sure that the moves are legal, apply the moves to the board, and detect when the game is over.\n",
    "\n",
    "### Checking Moves\n",
    "\n",
    "A move must be both valid and legal: it must refer to a real square, and it must form a bracket with another piece of the same color with pieces of the opposite color in between."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid(move):\n",
    "    \"\"\"Is move a square on the board?\"\"\"\n",
    "    return isinstance(move, int) and move in squares()\n",
    "\n",
    "def opponent(player):\n",
    "    \"\"\"Get player's opponent piece.\"\"\"\n",
    "    return BLACK if player is WHITE else WHITE\n",
    "\n",
    "def find_bracket(square, player, board, direction):\n",
    "    \"\"\"\n",
    "    Find a square that forms a bracket with `square` for `player` in the given\n",
    "    `direction`. Returns None if no such squares exists.\n",
    "    \"\"\"\n",
    "    bracket = square + direction\n",
    "    if board[bracket] == player:\n",
    "        return None\n",
    "    opp = opponent(player)\n",
    "    while board[bracket] == opp:\n",
    "        bracket += direction\n",
    "    return None if board[bracket] in (OUTER, EMPTY) else bracket\n",
    "\n",
    "def is_legal(move, player, board):\n",
    "    \"\"\"Is this a legal move for the player?\"\"\"\n",
    "    hasbracket = lambda direction: find_bracket(move, player, board, direction)\n",
    "    return board[move] == EMPTY and any(map(hasbracket, DIRECTIONS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making Moves\n",
    "\n",
    "When the player makes a move, we need to update the board and flip all the bracketed pieces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_move(move, player, board):\n",
    "    \"\"\"Update the board to reflect the move by the specified player.\"\"\"\n",
    "    board[move] = player\n",
    "    for d in DIRECTIONS:\n",
    "        make_flips(move, player, board, d)\n",
    "    return board\n",
    "\n",
    "def make_flips(move, player, board, direction):\n",
    "    \"\"\"Flip pieces in the given direction as a result of the move by player.\"\"\"\n",
    "    bracket = find_bracket(move, player, board, direction)\n",
    "    if not bracket:\n",
    "        return\n",
    "    square = move + direction\n",
    "    while square != bracket:\n",
    "        board[square] = player\n",
    "        square += direction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monitoring Players"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class IllegalMoveError(Exception):\n",
    "    def __init__(self, player, move, board):\n",
    "        self.player = player\n",
    "        self.move = move\n",
    "        self.board = board\n",
    "        \n",
    "    def __str__(self):\n",
    "        return '{0} cannot move to square {1}'.format(PLAYERS[self.player], self.move)\n",
    "    \n",
    "def legal_moves(player, board):\n",
    "    \"\"\"Get a list of all legal moves for player.\"\"\"\n",
    "    return [sq for sq in squares() if is_legal(sq, player, board)]\n",
    "\n",
    "def any_legal_move(player, board):\n",
    "    \"\"\"Can player make any moves?\"\"\"\n",
    "    return any(is_legal(sq, player, board) for sq in squares())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it all together\n",
    "\n",
    "Each round consists of:\n",
    "-  Get a move from the current player.\n",
    "-  Apply it to the board.\n",
    "-  Switch players. If the game is over, get the final score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "move_number = 1 # The number of the move to be played\n",
    "\n",
    "def play(black_strategy, white_strategy):\n",
    "    \"\"\"Play a game of Othello and return the final board and score.\"\"\"\n",
    "    board = initial_board()\n",
    "    player = BLACK\n",
    "    strategy = lambda who: black_strategy if who == BLACK else white_strategy\n",
    "    move_number = 1\n",
    "    while player is not None:\n",
    "        move = get_move(strategy(player), player, board)\n",
    "        make_move(move, player, board)\n",
    "        player = next_player(board, player)\n",
    "        move_number += 1\n",
    "    return board, score(BLACK, board)\n",
    "\n",
    "def next_player(board, prev_player):\n",
    "    \"\"\"Which player should move next? Returns None if no legal moves exist.\"\"\"\n",
    "    opp = opponent(prev_player)\n",
    "    if any_legal_move(opp, board):\n",
    "        return opp\n",
    "    elif any_legal_move(prev_player, board):\n",
    "        return prev_player\n",
    "    return None\n",
    "\n",
    "def get_move(strategy, player, board):\n",
    "    \"\"\"Call strategy(player, board) to get a move.\"\"\"\n",
    "    copy = board[:] # copy the board to prevent cheating\n",
    "    move = strategy(player, copy)\n",
    "    if not is_valid(move) or not is_legal(move, player, board):\n",
    "        raise IllegalMoveError(player, move, copy)\n",
    "    return move\n",
    "\n",
    "def get_score(player, board):\n",
    "    \"\"\"Compute player's score (number of player's pieces minus opponent's).\"\"\"\n",
    "    mine, theirs = 0, 0\n",
    "    opp = opponent(player)\n",
    "    for sq in squares():\n",
    "        piece = board[sq]\n",
    "        if piece == player:\n",
    "            mine += 1\n",
    "        elif piece == opp:\n",
    "            theirs += 1\n",
    "    return mine - theirs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"strategies\"></a>\n",
    "\n",
    "## Play Strategies\n",
    "\n",
    "### Random\n",
    "\n",
    "The easiest strategy to implement: simply pick a move at random."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def random_strategy(player, board):\n",
    "    \"\"\"A strategy that always chooses a random legal move.\"\"\"\n",
    "    return random.choice(legal_moves(player, board))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"localmax\"></a>\n",
    "\n",
    "### Local Maximization\n",
    "\n",
    "A more sophisticated strategy could look at every available move and evaluate them in some way. This consists of getting a list of legal moves, applying each one to a copy of the board, and choosing the move that results in the \"best\" board."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maximizer(evaluate):\n",
    "    \"\"\"\n",
    "    Construct a strategy that chooses the best move by maximizing\n",
    "    evaluate(player, board) over all boards resulting from legal moves.\n",
    "    \"\"\"\n",
    "    def strategy(player, board):\n",
    "        def score_move(move):\n",
    "            return evaluate(player, make_move(move, player, board[:]))\n",
    "        return max(legal_moves(player, board), key=score_move)\n",
    "    return strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One possible evaluation function is `score`. A strategy constructed with `maximizer(score)` will always make the move that results in the largest immediate gain in pieces.\n",
    "\n",
    "A more advanced evaluation function might consider the relative worth of each square on the board and weight the score by the value of the pieces held by each player. Since corners and (most) edge squares are very valuable, we could weight those more heavily, and add negative weights to the squares that, if acquired, could lead to the opponent capturing the corners or edges.\n",
    "\n",
    "<img src='files/img/weighted.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SQUARE_WEIGHTS = [\n",
    "    0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
    "    0, 120, -20,  20,   5,   5,  20, -20, 120,   0,\n",
    "    0, -20, -40,  -5,  -5,  -5,  -5, -40, -20,   0,\n",
    "    0,  20,  -5,  15,   3,   3,  15,  -5,  20,   0,\n",
    "    0,   5,  -5,   3,   3,   3,   3,  -5,   5,   0,\n",
    "    0,   5,  -5,   3,   3,   3,   3,  -5,   5,   0,\n",
    "    0,  20,  -5,  15,   3,   3,  15,  -5,  20,   0,\n",
    "    0, -20, -40,  -5,  -5,  -5,  -5, -40, -20,   0,\n",
    "    0, 120, -20,  20,   5,   5,  20, -20, 120,   0,\n",
    "    0,   0,   0,   0,   0,   0,   0,   0,   0,   0\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A strategy constructed as `maximizer(weighted_score)`, then will always return the move that results in the largest immediate \"weighted\" gain in pieces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_score(player, board):\n",
    "    \"\"\"\n",
    "    Compute the difference between the sum of the weights of player's\n",
    "    squares and the sum of the weights of opponent's squares.\n",
    "    \"\"\"\n",
    "    opp = opponent(player)\n",
    "    total = 0\n",
    "    for sq in squares():\n",
    "        if board[sq] == player:\n",
    "            total += SQUARE_WEIGHTS[sq]\n",
    "        elif board[sq] == opp:\n",
    "            total -= SQUARE_WEIGHTS[sq]\n",
    "    return total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a greedy strategy however, and will result in a local optimum, as the accepted optimal strategy for Othello is to centralize and maximize mobility (the amount of legal moves available to you) by minimizing your pieces and restricting the opponent's mobility.\n",
    "\n",
    "<img src='files/img/greedy.png'>\n",
    "\n",
    "We could construct an evaluation function `mobility`. A strategy constructed with `maximizer(mobility)` will always make the move that results in the largest immediate gain in mobility.\n",
    "\n",
    "We define _current mobility_ as the number of legal moves available to a player, and _potential mobility_ as the number of blank squares that are adjacent to opponent's pieces (called _frontier discs_). These include the legal moves. A better measure of mobility would try to count only good moves. The following function computes both current and potential mobility for a player:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adj(square):\n",
    "    \"\"\"List all the neighbors of a square.\"\"\"\n",
    "    return [square + d for d in DIRECTIONS]\n",
    "\n",
    "def mobility(player, board):\n",
    "    \"\"\"\n",
    "    Current mobility is the number of legal moves.\n",
    "    Potential mobility is the number of blank squares\n",
    "    adjacent to an opponent that are not legal moves.\n",
    "    Returns current and potential mobility for player.\n",
    "    \"\"\"\n",
    "    opp = opponent(player)\n",
    "    current, potential = 0, 0\n",
    "    for sq in squares():\n",
    "        if board[sq] == EMPTY:\n",
    "            if sq in legal_moves(player, board):\n",
    "                current += 1\n",
    "            elif any(board[neighbor] == opp for neighbor in adj[sq]):\n",
    "                potential += 1\n",
    "    return current, (current + potential)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"minimax\"></a>\n",
    "\n",
    "### Minimax search\n",
    "\n",
    "The maximizer strategies are very short-sighted, and a player who can consider the implications of a move several turns in advance could have a significant advantage. We can improve the strategy by searching ahead. Instead of choosing the move that leads immediately to the highest score, we can also consider the opponent's possible replies, our replies to those replies, and so on. By searching through several levels of moves, we can steer away from potential disaster and find good moves that were not immediately apparent.\n",
    "\n",
    "<img src='files/img/minimax.png'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimax(player, board, depth, evaluate):\n",
    "    \"\"\"\n",
    "    Find the best legal move for player, searching to the specified depth.\n",
    "    Returns a tuple (min_score, move), where min_score is the guaranteed minimum\n",
    "    score achievable for player if the move is made.\n",
    "    \"\"\"\n",
    "    \n",
    "    # We define the value of a board to be the opposite of its value to our\n",
    "    # opponent, computed by recursively applying `minimax` for our opponent.\n",
    "    def value(board):\n",
    "        return -minimax(opponent(player), board, depth-1, evaluate)[0]\n",
    "    \n",
    "    # When depth is zero, don't examine possible moves. Just determine the value\n",
    "    # of this board to the player.\n",
    "    if depth == 0:\n",
    "        return evaluate(player, board), None\n",
    "    \n",
    "    # We want to evaluate all the legal moves by considering their implications\n",
    "    # `depth` turns in advance. First, find all the legal moves.\n",
    "    moves = legal_moves(player, board)\n",
    "    \n",
    "    # If player has no legal moves, then either:\n",
    "    if not moves:\n",
    "        # the game is over, so the best achievable score is victory or defeat\n",
    "        if not any_legal_move(opponent(player), board):\n",
    "            return final_value(player, board), None\n",
    "        # or we have to pass this turn, so just find the value of this board.\n",
    "        return value(board), None\n",
    "    \n",
    "    # When there are multiple legal moves available, choose the best one by\n",
    "    # maximizing the value of the resulting boards.\n",
    "    return max((value(make_move(m, player, board[:])), m) for m in moves)\n",
    "\n",
    "# Values for endgame boards are big constants\n",
    "MAX_VALUE = float('inf')\n",
    "MIN_VALUE = float('-inf')\n",
    "\n",
    "def final_value(player, board):\n",
    "    \"\"\"The game is over. Find the value of this board to player.\"\"\"\n",
    "    diff = score(player, board)\n",
    "    if diff < 0:\n",
    "        return MIN_VALUE\n",
    "    elif diff > 0:\n",
    "        return MAX_VALUE\n",
    "    return diff\n",
    "\n",
    "def minimax_searcher(depth, evaluate):\n",
    "    \"\"\"\n",
    "    Construct a strategy that uses `minimax` with the specified leaf board\n",
    "    evaluation function.\n",
    "    \"\"\"\n",
    "    def strategy(player, board):\n",
    "        return minimax(player, board, depth, evaluate)[1]\n",
    "    return strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"alphabeta\"></a>\n",
    "\n",
    "### Alpha-Beta Search\n",
    "\n",
    "Minimax is very effective, but it does too much work: it evaluates many search trees that should be ignored.\n",
    "\n",
    "Consider what happens when minimax is evaluating two moves, M1 and M2, on one level of a search tree. Suppose minimax determines that M1 can result in a score of S. While evaluating M2, if minimax finds a move in its subtree that could result in a better score than S, the algorithm should immediately quit evaluating M2: the opponent will force us to play M1 to avoid the higher score resulting from M2, so we shouldn't waste time determining just how much better M2 is than M1.\n",
    "\n",
    "<img src='files/img/alphabeta.png'>\n",
    "\n",
    "We need to keep track of two values:\n",
    "-  __alpha:__ the maximum score achievable by any of the moves we have encountered.\n",
    "-  __beta:__ the score that the opponent can keep us under by playing other moves.\n",
    "\n",
    "When the algorithm begins, alpha is the smallest value and beta is the largest value. During evaluation, if we find a move that causes `alpha >= beta`, then we can quit searching this subtree since the opponent can prevent us from playing it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alphabeta(player, board, alpha, beta, depth, evaluate):\n",
    "    \"\"\"\n",
    "    Find the best legal move for player, searching to the specified depth.\n",
    "    Like minimax but uses the bounds alpha and beta to prune branches.\n",
    "    \"\"\"\n",
    "    if depth == 0:\n",
    "        return evaluate(player, board), None\n",
    "    \n",
    "    def value(board, alpha, beta):\n",
    "        # Like in `minimax`, the value of a board is the opposite of its value\n",
    "        # to the opponent. We pass in `-beta` and `-alpha` as the alpha and\n",
    "        # beta values, respectively, for the opponent, since `alpha` represents\n",
    "        # the best score we know we can achieve and is therefore the worst score\n",
    "        # achievable by the opponent. Similary, `beta` is the worst score that\n",
    "        # our opponent can hold us to, so it is the best score that they can\n",
    "        # achieve.\n",
    "        return -alphabeta(opponent(player), board, -beta, -alpha, depth-1, evaluate)[0]\n",
    "    \n",
    "    moves = legal_moves(player, board)\n",
    "    if not moves:\n",
    "        if not any_legal_move(opponent(player), board):\n",
    "            return final_value(player, board), None\n",
    "        return value(board, alpha, beta), None\n",
    "    \n",
    "    best_move = moves[0]\n",
    "    for move in moves:\n",
    "        if alpha >= beta:\n",
    "            # If one of the legal moves leads to a better score than beta, then\n",
    "            # the opponent will avoid this branch, so we can quit looking.\n",
    "            break\n",
    "        val = value(make_move(move, player, board[:]), alpha, beta)\n",
    "        if val > alpha:\n",
    "            # If one of the moves leads to a better score than the current best\n",
    "            # achievable score, then replace it with this one.\n",
    "            alpha = val\n",
    "            best_move = move\n",
    "    return alpha, best_move\n",
    "\n",
    "def alphabeta_searcher(depth, evaluate):\n",
    "    def strategy(player, board):\n",
    "        return alphabeta(player, board, MIN_VALUE, MAX_VALUE, depth, evaluate)[1]\n",
    "    return strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alpha-Beta v2.0 - Move Ordering\n",
    "\n",
    "The alpha-beta cutoffs work when we have established a good move and another move proves to be not as good. Thus, we will be able to make cutoffs earlier if we ensure that good moves are considered first. Our current algorithm loops through the list of `legal_moves`, but `legal_moves` makes no attempt to order the moves in any way. We will call this the _random-ordering_ strategy (even though the ordering is not random at all, square 11 is always considered first, then 12, etc.).\n",
    "\n",
    "One way to try to generate good moves first is to search highly weighted squares first. Since `legal_moves` considers squares in the order defined by `squares`, all we have to do is redefine the list `squares`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squares():\n",
    "    \"\"\"\n",
    "    List all the valid squares on the board\n",
    "    sorted from highest to lowest weight.\n",
    "    \"\"\"\n",
    "    return sorted([i for i in range(11, 89) if 1 <= (i % 10) <= 8], key=lambda sq: SQUARE_WEIGHTS[sq], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the corner squares will automatically be considered first, followed by the other highly weighted squares. We call this the _static-ordering_ strategy, because the ordering is not random, but it does not change depending on the situation.\n",
    "\n",
    "A more informed way to try to generate good moves first is to sort the moves according to the evaluation function. This means making more evaluations. Previously, only the boards at the leaves of the search tree were evaluated. Now we need to evaluate every board. In order to avoid evaluating a board more than once, we make up a structure called a `node`, which holds a board, the square that was taken to result in that board, and the evaluation value of that board.\n",
    "\n",
    "```\n",
    "node = [square, board, value]\n",
    "```\n",
    "\n",
    "The search is the same except that nodes are passed around instead of boards, and the nodes are sorted by their value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alphabeta2(player, node, alpha, beta, depth, evaluate):\n",
    "    \"\"\"\n",
    "    Alphabeta search, sorting moves by evaluation function\n",
    "    \"\"\"\n",
    "    if depth == 0:\n",
    "        return node[2], node\n",
    "\n",
    "    def value(node, alpha, beta):\n",
    "        return -alphabeta2(opponent(player), negate_value(node), -beta, -alpha, depth-1, evaluate)[0]\n",
    "    \n",
    "    board = node[1]\n",
    "    nodes = legal_nodes(player, board, evaluate)\n",
    "    \n",
    "    if not nodes:\n",
    "        if not any_legal_move(opponent(player), board):\n",
    "            return final_value(player, board), None\n",
    "        return value(node, alpha, beta), None\n",
    "    \n",
    "    best_node = nodes[0]\n",
    "    for move in nodes:\n",
    "        if alpha >= beta:\n",
    "            # If one of the legal moves leads to a better score than beta, then\n",
    "            # the opponent will avoid this branch, so we can quit looking.\n",
    "            break\n",
    "        val = value(move, alpha, beta)\n",
    "        if val > alpha:\n",
    "            # If one of the moves leads to a better score than the current best\n",
    "            # achievable score, then replace it with this one.\n",
    "            alpha = val\n",
    "            best_node = move\n",
    "    return alpha, best_node\n",
    "\n",
    "def negate_value(node):\n",
    "    \"\"\"Set the value of a node to its negative.\"\"\"\n",
    "    node[2] = -node[2]\n",
    "    return node\n",
    "\n",
    "def legal_nodes(player, board, evaluate):\n",
    "    \"\"\"Return a list of legal moves, each one packed into a node.\"\"\"\n",
    "    def fn(move):\n",
    "        new_board = make_move(move, player, board[:])\n",
    "        return [move, new_board, evaluate(player, new_board)]\n",
    "    moves = legal_moves(player, board)\n",
    "    nodes = sorted([fn(move) for move in moves], key=lambda node: node[2], reverse=True)\n",
    "    return nodes\n",
    "    \n",
    "def alphabeta_searcher2(depth, evaluate):\n",
    "    \"\"\"Return a strategy that does Alphabeta search with sorted moves.\"\"\"\n",
    "    def strategy(player, board):\n",
    "        node = [None, board, evaluate(player, board)]\n",
    "        return alphabeta2(player, node, MIN_VALUE, MAX_VALUE, depth, evaluate)[1][0]\n",
    "    return strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alpha-Beta v3.0 - Killer Instinct\n",
    "\n",
    "We saw before that the search routines look at tens of thousands of boards per move. Currently, each board position is created anew by `board[:]` and discarded soon thereafter. We could avoid generating all this garbage by reusing the same board at each depth. We'd still need to keep the board from the previous depth for use when the search backs up. Thus, a vector of boards is needed. In the following we assume that we will never search deeper than 40 depth. This is a safe assumption, as even the fastest Othello programs can only search about 15 depth before running out of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ply_boards = [initial_board() for _ in range(40)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous section, we considered to possibility of searching moves in a different order, in an attempt to search the better moves first, thereby getting more alpha-beta pruning. In this section, we consider the _killer heuristic_, which states that a move that has proven to be a good one in one line of play is also likely to be a good one in another line of play. To use chess as perhaps a more familiar example, suppose I consider one move, and it leads to the opponent replying by capturing my queen. This is a killer move, one that I would like to avoid. Therefore, when I consider other possible moves, I want to immediately consider the possibility of the opponent making that queen-capturing move.\n",
    "\n",
    "The function `alphabeta3` adds the parameter `killer`, which is the best move found so far at the current level. After we determine the `legal_moves`, we use `put_first` to put the killer move first, if it is in fact a legal move. When it comes time to search the next level, we keep track of the best move in `killer2`. This requires keeping track of the value of the best move in `killer2_val`. Everything else is unchanged, except that we get a new board by recycling the `ply_boards` vector rather than by allocating fresh ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alphabeta3(player, board, alpha, beta, depth, evaluate, killer):\n",
    "    \"\"\"\n",
    "    Alphabeta search, putting killer move first.\n",
    "    \"\"\"\n",
    "    if depth == 0:\n",
    "        return evaluate(player, board), None\n",
    "    \n",
    "    def value(board, alpha, beta, killer):\n",
    "        val, reply = alphabeta3(opponent(player), board, -beta, -alpha, depth-1, evaluate, killer)\n",
    "        return -val, reply\n",
    "    \n",
    "    moves = put_first(killer, legal_moves(player, board))\n",
    "    if not moves:\n",
    "        if not any_legal_move(opponent(player), board):\n",
    "            return final_value(player, board), None\n",
    "        return value(board, alpha, beta, None)[0], None\n",
    "    \n",
    "    best_move = moves[0]\n",
    "    new_board = ply_boards[depth]\n",
    "    killer2 = None\n",
    "    killer2_val = MAX_VALUE\n",
    "    for move in moves:\n",
    "        if alpha >= beta:\n",
    "            # If one of the legal moves leads to a better score than beta, then\n",
    "            # the opponent will avoid this branch, so we can quit looking.\n",
    "            break\n",
    "        val, reply = value(make_move(move, player, replace(new_board, board)), alpha, beta, killer2)\n",
    "        if val > alpha:\n",
    "            # If one of the moves leads to a better score than the current best\n",
    "            # achievable score, then replace it with this one.\n",
    "            alpha = val\n",
    "            best_move = move\n",
    "        if reply is not None and val < killer2_val:\n",
    "            # If one of the moves leads to a reply that is worse than our worst\n",
    "            # case scenario killer2, then replace it with this one.\n",
    "            killer2 = reply\n",
    "            killer2_val = val\n",
    "    return alpha, best_move\n",
    "\n",
    "def put_first(killer, moves):\n",
    "    \"\"\"\n",
    "    Move the killer move to the front of moves,\n",
    "    if the killer move is in fact a legal move.\n",
    "    \"\"\"\n",
    "    if killer in moves:\n",
    "        moves.insert(0, moves.pop(moves.index(killer)))\n",
    "    return moves\n",
    "\n",
    "def replace(seq1, seq2):\n",
    "    \"\"\"Copies one sequence into another\"\"\"\n",
    "    seq1[:] = seq2\n",
    "    return seq1\n",
    "    \n",
    "def alphabeta_searcher3(depth, evaluate):\n",
    "    \"\"\"Return a strategy that does Alphabeta search with killer moves\"\"\"\n",
    "    def strategy(player, board):\n",
    "        return alphabeta3(player, board, MIN_VALUE, MAX_VALUE, depth, evaluate, None)[1]\n",
    "    return strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Championship Programs: Iago and Bill\n",
    "As mentioned in the introduction, the unpredictability of Othello makes it a difficult game for humans to master, and thus programs that search deeply can do comparatively well. In fact, in 1981 the reigning champion, Jonathan Cerf, proclaimed \"In my opinion the top programs ... are now equal (if not superior) to the best human players.\" In discussing Rosenbloom's Iago program (1982), Cerf went on to say \"I understand Paul Rosenbloom is interested in arranging a match against me. Unfortunately my schedule is very full, and I'm going to see that it remains that way for the foreseeable future.\"\n",
    "\n",
    "In 1989, another program, Bill (Lee and Mahajan 1990) beat the highest rated American Othello player, Brian Rose, by a score of 56-8. Bill's evaluation function is fast enough to search 6-8 depths under tournament conditions, yet it is so accurate that it beats its creator, Kai-Fu Lee, searching only 1 depth. (However, Lee is only a novice Othello player; his real interest is in speech recognition; see Waibel and Lee 1991.) There are other programs that also play at a high level, but they have not been written up in the AI literature as Iago and Bill have.\n",
    "\n",
    "In this section we present an evaluation function based on Iago's, although it also contains elements of Bill, and of an evaluation function written by Eric Wefald in 1989. The evaluation function makes use of two main features: _mobility_ and _edge stability_.\n",
    "\n",
    "### Edge Stability\n",
    "\n",
    "Success at Othello often hinges around edge play, and both Iago and Bill evaluate the edges carefully. Edge analysis is made easier by the fact that the edges are fairly independent of the interior of the board: once a piece is placed on the edge, no interior moves can flip it. This independence allows a simplifying assumption: to evaluate a position's edge strength, evaluate each of the four edges independently, without consideration of the interior of the board. The evaluation can be made more accurate by considering the X-squares to be part of the edge.\n",
    "\n",
    "Even evaluating a single edge is a time-consuming task, so Bill and Iago compile away the evaluation by building a table of all possible edge positions. An \"edge\" according to Bill is ten squares: the eight actual edge squares and the two X-squares. Since each square can be black, white, or empty, there are 310 or 59,049 possible edge positions-a large but manageable number.\n",
    "\n",
    "The value of each edge position is determined by a process of successive approximation. Just as in a minimax search, we will need a static edge evaluation function to determine the value of an edge position without search. This static edge evaluation function is applied to every possible edge position, and the results are stored in a 59,049 element vector. The static evaluation is just a weighted sum of the occupied squares, with different weights given depending on if the piece is stable or unstable.\n",
    "\n",
    "Each edge position's evaluation can be improved by a process of search. Iago uses a single depth search: given a position, consider all moves that could be made (including no move at all). Some moves will be clearly legal, because they flip pieces on the edge, but other moves will only be legal if there are pieces in the interior of the board to flip. Since we are only considering the edge, we don't know for sure if these moves are legal. They will be assigned probabilities of legality. The updated evaluation of a position is determined by the values and probabilities of each move. This is done by sorting the moves by value and then summing the product of the value times the probability that the move can be made. This process of iterative approximation is repeated five times for each position. At that point, Rosenbloom reports, the values have nearly converged.\n",
    "\n",
    "In effect, this extends the depth of the normal alpha-beta search by including an edge-only search in the evaluation function. Since each edge position with _n_ pieces is evaluated as a function of the positions with _n + 1_ pieces, the search is complete - it is an implicit 10-depth search.\n",
    "\n",
    "Calculating edge stability is a bit more complicated than the other features. The first step is to define a variable, `edge_table`, which will hold the evaluation of each edge position, and a constant, `edge_and_x_lists`, which is a list of the squares on each of the four edges. Each edge has ten squares because the X-squares are included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Array of values for edge positions\n",
    "edge_table = [0 for _ in range(3**10)]\n",
    "\n",
    "# The four edges (with their X-squares)/\n",
    "edge_and_x_lists = [[22, 11, 12, 13, 14, 15, 16, 17, 18, 27],\n",
    "                    [72, 81, 82, 83, 84, 85, 86, 87, 88, 77],\n",
    "                    [22, 11, 21, 31, 41, 51, 61, 71, 81, 72],\n",
    "                    [27, 18, 28, 38, 48, 58, 68, 78, 88, 77]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for each edge we can compute an index into the edge table by building a 10-digit base-3 number, where each digit is 1 if the corresponding edge square is occupied by the player, 2 if by the opponent, and 0 if empty. The function `edge_index` computes this, and `edge_stability` sums the values of the four edge indexes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_index(player, board, squares):\n",
    "    \"\"\"The index counts 1 for player; 2 for opponent,\n",
    "    on each square -- summed as a base 3 number.\"\"\"\n",
    "    opp = opponent(player)\n",
    "    index = 0\n",
    "    for sq in squares:\n",
    "        index *= 3\n",
    "        if board[sq] == player:\n",
    "            index += 1\n",
    "        elif board[sq] == opp:\n",
    "            index += 2\n",
    "    return index\n",
    "\n",
    "def edge_stability(player, board):\n",
    "    \"\"\"Total edge evaluation for player\"\"\"\n",
    "    score = sum(edge_table[edge_index(player, board, edge)] for edge in edge_and_x_lists)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `edge_stability` is all we will need in Iago's evaluation function, but we still need to generate the edge table. Since this needs to be done only once, we don't have to worry about efficiency. In particular, rather than invent a new data structure to represent edges, we will continue to use complete boards, even though they will be mostly empty. The computations for the edge table will be made on the top edge, from the point of view of black, with black to play. But the same table can be used for white, or for one of the other edges, because of the way the edge index is computed.\n",
    "\n",
    "Each position in the table is first initialized to a static value computed by a kind of weighted-squares metric, but with different weights depending on if a piece is in danger of being captured. After that, each position is updated by considering the possible moves that can be made from the position, and the values of each of these moves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_edge = edge_and_x_lists[0]\n",
    "\n",
    "def init_edge_table():\n",
    "    \"\"\"Initialize `edge_table`, starting from the empty board.\"\"\"\n",
    "    # Initialize the static values\n",
    "    for n_pieces in range(11):\n",
    "        def fn(board, index):\n",
    "            edge_table[index] = static_edge_stability(BLACK, board)\n",
    "        map_edge_n_pieces(fn, BLACK, initial_board(), n_pieces, top_edge, 0)\n",
    "    # Now iterate five times trying to improve\n",
    "    for _ in range(5):\n",
    "        for n_pieces in range(9, 0, -1):\n",
    "            def fn(board, index):\n",
    "                edge_table[index] = possible_edge_moves_value(BLACK, board, index)\n",
    "            map_edge_n_pieces(fn, BLACK, initial_board(), n_pieces, top_edge, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `map_edge_n_pieces` iterates through all edge positions with a total of `n` pieces (of either color), applying a function to each such position. It also keeps a running count of the edge index as it goes. The function should accept two arguments: the board and the index. Note that a single board can be used for all the positions because squares are reset after they are used. The function has three cases: if the number of squares remaining is less than `n`, then it will be impossible to place `n` pieces on those squares, so we give up. If there are no more squares then `n` must also be zero, so this is a valid position, and the function `fn` is called. Otherwise we first try leaving the current square blank, then try filling it with player's piece, and then with the opponent's piece, in each case calling `map_edge_n_pieces` recursively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_edge_n_pieces(fn, player, board, n, squares, index):\n",
    "    \"\"\"\n",
    "    Call fn on all edges with n pieces.\n",
    "    Index counts 1 for player, 2 for opponent\n",
    "    \"\"\"\n",
    "    if len(squares) < n:\n",
    "        return\n",
    "    elif not squares:\n",
    "        fn(board, index)\n",
    "    else:\n",
    "        index3 = index * 3\n",
    "        sq = squares[0]\n",
    "        map_edge_n_pieces(fn, player, board, n, squares[1:], index3)\n",
    "        if n > 0 and board[sq] == EMPTY:\n",
    "            board[sq] = player\n",
    "            map_edge_n_pieces(fn, player, board, n-1, squares[1:], index3+1)\n",
    "            board[sq] = opponent(player)\n",
    "            map_edge_n_pieces(fn, player, board, n-1, squares[1:], index3+2)\n",
    "            board[sq] = EMPTY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `possible_edge_moves_value` searches through all possible moves to determine an edge value that is more accurate than a static evaluation. It loops through every empty square on the edge, calling `possible_edge_move` to return a (_probability value_) pair. Since it is also possible for a player not to make any move at all on an edge, the pair (`1.0`, _current value_) is also included."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def possible_edge_moves_value(player, board, index):\n",
    "    \"\"\"\n",
    "    Consider all possible edge moves.\n",
    "    Combine their values into a single number.\n",
    "    \"\"\"\n",
    "    x = [(1.0, edge_table[index])]\n",
    "    y = [possible_edge_move(player, board, sq) for sq in top_edge if board[sq] == EMPTY]\n",
    "    possibilities = x + y\n",
    "    return combine_edge_moves(possibilities, player)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value of each position is determined by making the move on the board, then looking up in the table the value of the resulting position for the opponent, and negating it (since we are interested in the value to us, not to our opponent)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def possible_edge_move(player, board, sq):\n",
    "    \"\"\"Return a (prob, val) pair for a possible edge move.\"\"\"\n",
    "    num_player = 1 if player == BLACK else 2\n",
    "    new_board = replace(ply_boards[num_player], board)\n",
    "    make_move(sq, player, new_board)\n",
    "    prob = edge_move_probability(player, board, sq)\n",
    "    val = -edge_table[edge_index(opponent(player), new_board, top_edge)]\n",
    "    return (prob, val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The possible moves are combined with `combine_edge_moves`, which sorts the moves best-first. (Since `init_edge_table` started from black's perspective, black tries to maximize and white tries to minimize scores.) We then go down the moves, increasing the total value by the value of each move times the probability of the move, and decreasing the remaining probability by the probability of the move. Since there will always be at least one move (pass) with probability 1.0, this is guaranteed to converge. In the end, we round off the total value, so that we can do the run-time calculations with integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_edge_moves(possibilities, player):\n",
    "    \"\"\"Combine the best moves.\"\"\"\n",
    "    prob = 1.0\n",
    "    val = 0.0\n",
    "    fn = True if player == BLACK else False\n",
    "    for pair in sorted(possibilities, key=lambda x: x[1], reverse=fn):\n",
    "        if prob < 0.0:\n",
    "            break\n",
    "        val += prob * pair[0] * pair[1]\n",
    "        prob -= prob * pair[0]\n",
    "    return round(val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still need to compute the probability that each possible edge move is legal. These probabilities should reflect things such as the fact that it is easy to capture a corner if the opponent is in the adjacent X-square, and very difficult otherwise. First we define some functions to recognize corner and X-squares and relate them to their neighbors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "corner_xsqs = [(11, 22), (18, 27), (81, 72), (88, 77)]\n",
    "\n",
    "def corner_p(sq):\n",
    "    \"\"\"Return the tuple which contains the corner square\"\"\"\n",
    "    return next((x for x in corner_xsqs if x[0] == sq), None)\n",
    "\n",
    "def x_square_p(sq):\n",
    "    \"\"\"Return the tuple which contains the x-square\"\"\"\n",
    "    return next((x for x in corner_xsqs if x[1] == sq), None)\n",
    "\n",
    "def x_square_for(corner):\n",
    "    \"\"\"Return the x-square for a corner square\"\"\"\n",
    "    tuple = [x for x in corner_xsqs if x[0] == corner]\n",
    "    return tuple[0][1] if tuple else None\n",
    "\n",
    "def corner_for(xsq):\n",
    "    \"\"\"Return the corner square for an x-square\"\"\"\n",
    "    tuple = [x for x in corner_xsqs if x[1] == xsq]\n",
    "    return tuple[0][0] if tuple else None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we consider the probabilities. There are four cases. First, since we don't know anything about the interior of the board, we assume each player has a 50% chance of being able to play in an X-square. Second, if we can show that a move is legal (because it flips opponent pieces on the edge) then it has 100% probability. Third, for the corner squares, we assign a 90% chance if the opponent occupies the X-square, 10% if it is empty and only .1% if we occupy it. Otherwise, the probability is determined by the two neighboring squares: if a square is next to one or more opponents, it is more likely we can move there; if it is next to our pieces it is less likely. If it is legal for the opponent to move into the square, then the chances are cut in half (although we may still be able to move there, since we move first)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def edge_move_probability(player, board, square):\n",
    "    \"\"\"What's the probability that player can move to this square?\"\"\"\n",
    "    # X-squares\n",
    "    if x_square_p(square):\n",
    "        return 0.5\n",
    "    # Immediate capture\n",
    "    elif is_legal(square, player, board):\n",
    "        return 1.0\n",
    "    # Move to corner depends on X-square\n",
    "    elif corner_p(square):\n",
    "        x_square = x_square_for(square)\n",
    "        if board[x_square] == EMPTY:\n",
    "            return 0.1\n",
    "        elif board[x_square] == player:\n",
    "            return 0.001\n",
    "        else:\n",
    "            return 0.9\n",
    "    else:\n",
    "        val = [[.1, .4, .7],\n",
    "               [.05, .3, None],\n",
    "               [.01, None, None]]\n",
    "        x = count_edge_neighbors(player, board, square)\n",
    "        y = count_edge_neighbors(opponent(player), board, square)\n",
    "        if is_legal(square, opponent(player), board):\n",
    "            return val[x][y]/2\n",
    "        else:\n",
    "            return val[x][y]\n",
    "        \n",
    "def count_edge_neighbors(player, board, square):\n",
    "    \"\"\"Count the neighbors of this square occupied by player.\"\"\"\n",
    "    inc = [1, -1]\n",
    "    neighbors = [board[square+i] for i in inc]\n",
    "    return sum(1 for x in neighbors if x == player)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we return to the problem of determining the static value of an edge position. This is computed by a weighted-squares metric, but the weights depend on the _stability_ of each piece. A piece is called stable if it cannot be captured, unstable if it is in immediate danger of being captured, and semistable otherwise. A table of weights follows for each edge square and stability. Note that corner squares are always stable, and X-squares we will call semistable if the adjacent corner is taken, and unstable otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#                     stab  semi  un\n",
    "static_edge_table = [[None, 0, -2000],  # X\n",
    "                     [700, None, None], # corner\n",
    "                     [1200, 200, -25],  # C\n",
    "                     [1000, 200, 75],   # A\n",
    "                     [1000, 200, 50],   # B\n",
    "                     [1000, 200, 50],   # B\n",
    "                     [1000, 200, 75],   # A\n",
    "                     [1200, 200, -25],  # C\n",
    "                     [700, None, None], # corner\n",
    "                     [None, 0, -2000]]  # X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The static evaluation then just sums each piece's value according to this table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def static_edge_stability(player, board):\n",
    "    \"\"\"Compute this edge's static stability.\"\"\"\n",
    "    score = 0\n",
    "    for i in range(len(top_edge)):\n",
    "        sq = top_edge[i]\n",
    "        if board[sq] == EMPTY:\n",
    "            score += 0\n",
    "        elif board[sq] == player:\n",
    "            score += static_edge_table[i][piece_stability(board, sq)]\n",
    "        else:\n",
    "            score -= static_edge_table[i][piece_stability(board, sq)]\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The computation of stability is fairly complex. It centers around finding the two \"pieces,\" `p1` and `p2`, which lay on either side of the piece in question and which are not of the same color as the piece. These \"pieces\" may be empty, or they may be off the board. A piece is unstable if one of the two is empty and the other is the opponent; it is semistable if there are opponents on both sides and at least one empty square to play on, or if it is surrounded by empty pieces. Finally, if either `p1` or `p2` is nil then the piece is stable, since it must be connected by a solid wall of pieces to the corner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def piece_stability(board, sq):\n",
    "    \"\"\"Evaluate whether a square is stable, unstable or semi-stable\"\"\"\n",
    "    stable, semi_stable, unstable = 0, 1, 2\n",
    "    if corner_p(sq):\n",
    "        return stable\n",
    "    elif x_square_p(sq):\n",
    "        if board[corner_for(sq)] == EMPTY:\n",
    "            return unstable\n",
    "        else:\n",
    "            return semi_stable\n",
    "    else:\n",
    "        player = board[sq]\n",
    "        opp = opponent(player)\n",
    "        p1 = next(p for p in board[sq:20] if p != player)\n",
    "        p2 = next(p for p in board[sq-1:9:-1] if p != player)\n",
    "        \n",
    "        # Unstable pieces can be captured immediately\n",
    "        # by playing in the empty square\n",
    "        if (p1 == EMPTY and p2 == opp) or (p2 == EMPTY and p1 == opp):\n",
    "            return unstable\n",
    "        \n",
    "        # Semi-stable pieces might be captured\n",
    "        elif p1 == opp and p2 == opp and next((p for p in board[11:19] if p == EMPTY), None):\n",
    "            return semi_stable\n",
    "        elif p1 == EMPTY and p2 == EMPTY:\n",
    "            return semi_stable\n",
    "        \n",
    "        # Stable pieces can never be captured\n",
    "        else:\n",
    "            return stable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The edge table can now be built by a call to `init_edge_table`. After the table is built once, it is a good idea to save it so that we won't need to repeat the initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save data into a file\n",
    "def save_data(filename, data):\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(' '.join(str(x) for x in data))\n",
    "\n",
    "# Load data from file\n",
    "def load_data(filename):\n",
    "    with open(filename) as f:\n",
    "        dataset = [int(x) for x in next(f).split()]\n",
    "    return dataset\n",
    "\n",
    "init_edge_table()\n",
    "save_data('edge_table.txt', edge_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining the Factors\n",
    "\n",
    "Now we have a measure of the three factors: current mobility, potential mobility and edge stability. All that remains is to find a good way to combine them into a single evaluation metric. The combination function used by Rosenbloom (1982) is a linear combination of the three factors, but each factor's coefficient is dependent on the move number. Rosenbloom's features are normalized to the range [-1000, 1000]; we normalize to the range [-1, 1] by doing a division after multiplying by the coefficient. That allows us to use integers for the coefficients. Since our three factors are not calculated in quite the same way as Rosenbloom's, it is not surprising that his coefficients are not the best for our program. The edge coefficient was doubled and the potential coefficient cut by a factor of five."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Iago_eval(player, board):\n",
    "    \"\"\"\n",
    "    Combine edge stability, current mobility and\n",
    "    potential mobility to arrive at an evaluation.\n",
    "    \"\"\"\n",
    "    # The three factors are multiplied by coefficients\n",
    "    # that vary by move number\n",
    "    c_edg = 312000 + 6240 * move_number\n",
    "    if move_number < 25:\n",
    "        c_cur = 50000 + 2000 * move_number\n",
    "    else:\n",
    "        c_cur = 75000 + 1000 * move_number\n",
    "    c_pot = 20000\n",
    "    \n",
    "    p_cur, p_pot = mobility(player, board)\n",
    "    o_cur, o_pot = mobility(opponent(player), board)\n",
    "    \n",
    "    score1 = round(c_edge * edge_stability(player, board) / 32000)\n",
    "    score2 = round(c_cur * (p_cur - o_cur) / (p_cur + o_cur + 2))\n",
    "    score3 = round(c_pot * (p_pot - o_pot) / (p_pot + o_pot + 2))\n",
    "    \n",
    "    score = score1 + score2 + score3\n",
    "    return score"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
